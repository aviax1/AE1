{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPry7tYjAUCQB3ohK2DttW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/ae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnlUAkduSqay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used snniped from https://github.com/L1aoXingyu/pytorch-beginner/\n",
        "import torch\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from multiprocessing import Process"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000     #\n",
        "batch_size = 64     #\n",
        "image_size=784      #\n",
        "hidden_size=64      #\n",
        "lv_size = 64        # Latent Variable \n",
        "learning_rate=1e-4  #\n",
        "cret = nn.MSELoss() # criterion"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size),   #nn.ReLU(True), nn.Linear(image_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size), nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train model by digit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_by_digit(by_digit,model):\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  for epoch in range(num_epochs):\n",
        "    run=(epoch%50==0)\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  model_name='./ae_'+str(by_digit)+'.pth'\n",
        "  torch.save(model.state_dict(),model_name )\n",
        "  wandb.save(model_name)\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")\n",
        "\n",
        "for by_digit in range(10):\n",
        "  train_by_digit(by_digit,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "8c2f4e06-ca1b-477d-8b6c-3b8680492627"
      },
      "source": [
        "nn=len(ytest)\n",
        "dataloader = DataLoader(DigitDataSet(xtest), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "for i in range(10):\n",
        "  for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      model_name='./ae_'+str(i)+'.pth'\n",
        "      tmodel.load_state_dict(torch.load(model_name))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "min_index=np.argmin(diff, axis=1)\n",
        "seccess =  min_index == ytest\n",
        "counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "plt.hist(bins[:-1], bins, weights=counts)\n",
        "plt.title(\"error by digit\")\n",
        "plt.show()\n",
        "print(str(int(10000*np.sum(seccess))/(nn*100)) + \"% seccess rate \")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "94.67% seccess rate \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}