{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKx0X6E+fzMwTm8fMdbFko",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/ae_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used snniped from https://github.com/L1aoXingyu/pytorch-beginner/\n",
        "!pip install wandb\n",
        "import torch\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from multiprocessing import Process"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000     #\n",
        "batch_size = 64     #\n",
        "image_size=784      #\n",
        "hidden_size=64      #\n",
        "lv_size = 64        # Latent Variable \n",
        "learning_rate=0.5*1e-4  #\n",
        "cret = nn.MSELoss() # criterion"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size),   #nn.ReLU(True), nn.Linear(image_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size), nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "068e35f7-d634-4ad7-d46e-b4ce9571824d"
      },
      "source": [
        "def testmodel():\n",
        "  nn=len(ytest)\n",
        "  dataloader = DataLoader(DigitDataSet(xtest), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      model_name='./ae_'+str(i)+'.pth'\n",
        "      tmodel.load_state_dict(torch.load(model_name))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  min_index=np.argmin(diff, axis=1)\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  print(str(int(10000*np.sum(seccess))/(nn*100)) + \"% seccess rate \")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "93.76% seccess rate \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train model by digit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "0064da6a-3c1b-4e90-89c3-b983e3a2f758"
      },
      "source": [
        "def save_model(digit,model):\n",
        "  model_name='./ae_'+str(digit)+'.pth'\n",
        "  torch.save(model.state_dict(),model_name )\n",
        "  wandb.save(model_name)\n",
        "  print(\"save model \"+ model_name)\n",
        "\n",
        "def train_by_digit(by_digit,model):\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=16)\n",
        "  for epoch in range(num_epochs):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%100==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "        \n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  save_model(by_digit,model)\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")\n",
        "\n",
        "for by_digit in range(5,10):\n",
        "  train_by_digit(by_digit,model)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/1ccwywje\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/1ccwywje</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 5\n",
            "\n",
            "epoch [1/1000], loss:0.0827\n",
            "epoch [2/1000], loss:0.0852\n",
            "epoch [3/1000], loss:0.0845\n",
            "epoch [4/1000], loss:0.0822\n",
            "epoch [5/1000], loss:0.0838\n",
            "epoch [6/1000], loss:0.0926\n",
            "epoch [7/1000], loss:0.0896\n",
            "epoch [8/1000], loss:0.0909\n",
            "epoch [9/1000], loss:0.0990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4f61c0052e5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mby_digit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mtrain_by_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby_digit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-4f61c0052e5a>\u001b[0m in \u001b[0;36mtrain_by_digit\u001b[0;34m(by_digit, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Error in callback <function _init_jupyter.<locals>.cleanup at 0x7f0f6d1f7ea0> (for post_run_cell):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/__init__.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# shutdown async logger because _user_process_finished isn't called in jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mshutdown_async_log_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_jupyter_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_orig_post_run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post_run_cell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_post_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/wandb_run.py\u001b[0m in \u001b[0;36m_stop_jupyter_agent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_stop_jupyter_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmirror_stdout_stderr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, exitcode)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloud\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stopping streaming files and file change observer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_file_syncing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36m_end_file_syncing\u001b[0;34m(self, exitcode)\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_observer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_observer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_observer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}