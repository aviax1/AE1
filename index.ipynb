{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNV5EU97dQN94AglSqiO6/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb\n",
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000        #\n",
        "batch_size = 64        #\n",
        "image_size=784         #\n",
        "hidden_size=96         #\n",
        "lv_size = 48           # Latent Variable \n",
        "learning_rate=1e-4     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "             nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "def get_prediction(data=xtest):\n",
        "  nn=len(data)\n",
        "  dataloader = DataLoader(DigitDataSet(data), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      tmodel.load_state_dict(torch.load(model_name(i)))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  return np.argmin(diff, axis=1)\n",
        "\n",
        "\n",
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  min_index =get_prediction()\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")\n",
        "  return counts, bins ,len(ytest[min_index != ytest]) , len(ytest)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model,ne=num_epochs,opt=optimizer):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  for epoch in range(ne):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "        \n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, ne, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  save_model(by_digit,model)\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ueJ9JLrWxQo",
        "colab_type": "text"
      },
      "source": [
        "**train new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlAu_FKWy9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for by_digit in range(10):\n",
        "  train_by_digit(by_digit,model,120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a45a97f9-0ed2-4677-9793-80e2498a3cac"
      },
      "source": [
        "_,_,_,_=testmodel()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "98.29% accuracy or 1.71% error rate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvTKuQcKae2",
        "colab_type": "text"
      },
      "source": [
        "**retrain the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-dF1c0OKfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traget_error=0.005\n",
        "error = 1\n",
        "while  error > traget_error:\n",
        "  counts,b,fail,total=testmodel()\n",
        "  error = float(fail/total)\n",
        "  if error > traget_error:\n",
        "    train_by_digit(np.argmax(counts),model,30, torch.optim.Adam(model.parameters(), lr=1e-3) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLThtP6wLbe",
        "colab_type": "text"
      },
      "source": [
        "**kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwJitYWwPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/kaggle.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1EI5LMwV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test=pd.read_csv('./test.csv')\n",
        "inputs_test=np.array(inputs_test,dtype=np.float32)\n",
        "inputs_test=inputs_test.reshape(inputs_test.shape[0],28,28)/255\n",
        "y=get_prediction(inputs_test)\n",
        "imageid=1\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "  spamwriter = csv.writer(csvfile, delimiter=' ',    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  spamwriter.writerow(['ImageId,Label'])\n",
        "  for yi in y:\n",
        "    spamwriter.writerow([str(imageid) +','+str( yi)])\n",
        "    imageid+=1\n",
        "#SCORE 0.99078"
      ],
      "execution_count": 57,
      "outputs": []
    }
  ]
}