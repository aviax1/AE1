{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5RzqNSSWF1lxBQg48H7rI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb\n",
        "import torch,wandb,os\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000        #\n",
        "batch_size = 64        #\n",
        "image_size=784         #\n",
        "hidden_size=64         #\n",
        "lv_size = 64           # Latent Variable \n",
        "learning_rate=1e-3 #\n",
        "cret = nn.MSELoss()    # criterion"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size),   #nn.ReLU(True), nn.Linear(image_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size), nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  dataloader = DataLoader(DigitDataSet(xtest), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      model_name='./ae_'+str(i)+'.pth'\n",
        "      tmodel.load_state_dict(torch.load(model_name))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  min_index=np.argmin(diff, axis=1)\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train model by digit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  model_name='./ae_'+str(digit)+'.pth'\n",
        "  torch.save(model.state_dict(),model_name )\n",
        "  wandb.save(model_name)\n",
        "  print(\"save model \"+ model_name)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  model_name='./ae_'+str(digit)+'.pth'\n",
        "  if os.path.isfile(model_name):\n",
        "    model.load_state_dict(torch.load(model_name))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  for epoch in range(num_epochs):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        #testmodel()\n",
        "        \n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  save_model(by_digit,model)\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")\n",
        "\n",
        "for by_digit in range(5,10):\n",
        "  train_by_digit(by_digit,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9fa1e66a-3492-446b-bea1-916f68489219"
      },
      "source": [
        "testmodel()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "97.53% accuracy or 2.47% error rate\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}