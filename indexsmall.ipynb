{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOaVjxwYHnHSe7C1+t1jpG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/indexsmall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RffrO5RiH_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "20ddefdf-bcf9-423c-c7d2-564e31fc13c6"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.9.5)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.16.5)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.3)\n",
            "Requirement already satisfied: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.2.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.7)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000        #\n",
        "batch_size = 64        #\n",
        "image_size=784         #\n",
        "hidden_size=58         #\n",
        "lv_size = 16           # Latent Variable \n",
        "learning_rate=1e-4     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "def get_prediction(data=xtest):\n",
        "  nn=len(data)\n",
        "  dataloader = DataLoader(DigitDataSet(data), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      tmodel.load_state_dict(torch.load(model_name(i)))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  return np.argmin(diff, axis=1)\n",
        "\n",
        "\n",
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  min_index =get_prediction()\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")\n",
        "  return counts, bins ,len(ytest[min_index != ytest]) , len(ytest)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model,ne=num_epochs,opt=optimizer):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  minloss=100000000\n",
        "  for epoch in range(ne):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      if minloss!=100000000:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "    newlost = float(loss.data ) \n",
        "    if newlost < minloss:\n",
        "        if minloss!=100000000:\n",
        "          save_model(by_digit,model)\n",
        "        minloss=newlost\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, ne, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  \n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ueJ9JLrWxQo",
        "colab_type": "text"
      },
      "source": [
        "**train new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlAu_FKWy9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "85cfda44-dd67-4918-db62-db898e591100"
      },
      "source": [
        "for i in range(10):\n",
        "  train_by_digit(i,model,100,torch.optim.Adam(model.parameters(), lr=1e-3))\n",
        "_,_,_,_=testmodel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/2jlwj290\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/2jlwj290</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 0\n",
            "\n",
            "epoch [1/100], loss:0.0314\n",
            "epoch [2/100], loss:0.0339\n",
            "save model ./ae_0.pth\n",
            "epoch [3/100], loss:0.0291\n",
            "epoch [4/100], loss:0.0326\n",
            "epoch [5/100], loss:0.0339\n",
            "epoch [6/100], loss:0.0371\n",
            "epoch [7/100], loss:0.0329\n",
            "epoch [8/100], loss:0.0318\n",
            "epoch [9/100], loss:0.0348\n",
            "epoch [10/100], loss:0.0310\n",
            "save model ./ae_0.pth\n",
            "epoch [11/100], loss:0.0286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:27.621755, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch [12/100], loss:0.0300\n",
            "epoch [13/100], loss:0.0379\n",
            "epoch [14/100], loss:0.0312\n",
            "epoch [15/100], loss:0.0307\n",
            "epoch [16/100], loss:0.0325\n",
            "epoch [17/100], loss:0.0345\n",
            "epoch [18/100], loss:0.0330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "58bad0f6-cdc6-407c-eaaa-730d329130cd"
      },
      "source": [
        "_,_,_,_=testmodel()\n",
        "!zip -r all.zip ./*.pth"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "98.07% accuracy or 1.93% error rate\n",
            "  adding: ae_0.pth (deflated 8%)\n",
            "  adding: ae_1.pth (deflated 8%)\n",
            "  adding: ae_2.pth (deflated 8%)\n",
            "  adding: ae_3.pth (deflated 8%)\n",
            "  adding: ae_4.pth (deflated 8%)\n",
            "  adding: ae_5.pth (deflated 8%)\n",
            "  adding: ae_6.pth (deflated 8%)\n",
            "  adding: ae_7.pth (deflated 8%)\n",
            "  adding: ae_8.pth (deflated 7%)\n",
            "  adding: ae_9.pth (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvTKuQcKae2",
        "colab_type": "text"
      },
      "source": [
        "**retrain the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-dF1c0OKfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traget_error=0.005\n",
        "error = 1\n",
        "while  error > traget_error:\n",
        "  counts,b,fail,total=testmodel()\n",
        "  error = float(fail/total)\n",
        "  if error > traget_error:\n",
        "    train_by_digit(np.argmax(counts),model,30, torch.optim.Adam(model.parameters(), lr=1e-3) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLThtP6wLbe",
        "colab_type": "text"
      },
      "source": [
        "**kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwJitYWwPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/kaggle.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1EI5LMwV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test=pd.read_csv('./test.csv')\n",
        "inputs_test=np.array(inputs_test,dtype=np.float32)\n",
        "inputs_test=inputs_test.reshape(inputs_test.shape[0],28,28)/255\n",
        "y=get_prediction(inputs_test)\n",
        "imageid=1\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "  spamwriter = csv.writer(csvfile, delimiter=' ',    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  spamwriter.writerow(['ImageId,Label'])\n",
        "  for yi in y:\n",
        "    spamwriter.writerow([str(imageid) +','+str( yi)])\n",
        "    imageid+=1\n",
        "#99.714% accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}