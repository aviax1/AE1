{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMP+na3hdcmkVdVJ5dqXRFb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used snniped from https://github.com/L1aoXingyu/pytorch-beginner/\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=200      #\n",
        "batch_size = 20    #\n",
        "image_size=784      #\n",
        "hidden_size=128     #\n",
        "lv_size = 64        # Latent Variable \n",
        "learning_rate=1e-4  #\n",
        "cret = nn.MSELoss() # criterion"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, image_size),nn.ReLU(True), nn.Linear(image_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size), nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])\n",
        "\n",
        "def images_row(dis_images,title,add_to_index=0, images_in_row=5):\n",
        "  if( len(np.shape(dis_images)) == 2):\n",
        "    dis_images=dis_images[0:images_in_row,:]\n",
        "  else:\n",
        "    dis_images=dis_images[0:images_in_row,0,:,:]\n",
        "  for i in range(len(dis_images)):\n",
        "    ax = plt.subplot(30, images_in_row, i+add_to_index + 1)\n",
        "    plt.imshow(dis_images[i].reshape(28, 28))\n",
        "    plt.title( title)\n",
        "    plt.gray()\n",
        "\n",
        "def visual_epoch(epoch_num,model,dataloader):\n",
        "  for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      images_row(input_imgs,\"org \",5*epoch_num)\n",
        "      images_row(output_imgs.detach().numpy(),\"rec \",5*(epoch_num+1))\n",
        "       "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train model by digit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "f181a3d4-2bb7-48fd-b999-916ac09dc620"
      },
      "source": [
        "for by_digit in range(10):\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  \n",
        "  visual_counter=0\n",
        "  for epoch in range(epoch_num):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #if epoch%3==0 :\n",
        "    #  visual_epoch(visual_counter,model,dataloader)\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    \n",
        "\n",
        "  torch.save(model.state_dict(), './ae_'+str(by_digit)+'.pth')\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n\")\n",
        "  print(\"*****\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch [1/200], loss:0.1634\n",
            "epoch [2/200], loss:0.1792\n",
            "epoch [3/200], loss:0.1434\n",
            "epoch [4/200], loss:0.1156\n",
            "epoch [5/200], loss:0.1279\n",
            "epoch [6/200], loss:0.1451\n",
            "epoch [7/200], loss:0.1151\n",
            "epoch [8/200], loss:0.1021\n",
            "epoch [9/200], loss:0.1138\n",
            "epoch [10/200], loss:0.0921\n",
            "\n",
            "finish traning Model Number 0\n",
            "\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAA8CAYAAAAaGRPjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOQklEQVR4nO2dfXBVZXrAf8/NvTeQYAAhi66ETUtFiI6U0gE7q5SkwyxGXYQxKLWmwg6s7TCzIJWVLePHVEz9WLt2qCi6Ls5KS6FshWmhWmatDl8LLCIQpBR3FoEKjRtwUQKB3Kd/vOfi5Z6EfNxzcu9Nnt/MGbjnnHvzvr/7vk9O3vc57xFVxTAMw/iKSLYLYBiGkWtYYDQMw0jDAqNhGEYaFhgNwzDSsMBoGIaRhgVGwzCMNCwwGoZhpGGB0TAMI42sBUYRKcjWz85lzIsfc+LHnPgJ0kmggVFERonIf4nIaRGpF5FvpxxbISLLRGSDiHwJVIrIH4jIByJyRkTWiMg/i8hTQZYpFzAvfsyJH3PiJ2tOVDWQDYgBh4EfAHGgCjgD3OAdXwF8DnwTF5BLgCPA97z3TgOagaeCKlMubObFnJiT/HMS5BXjLUA/4G9VtVlVfw78GzAj5Zx1qrpFVRPA7wNR4O9V9YKq/gzYEWB5cgXz4sec+DEnfrLmJMjA+HXgqFfAJEeA61JeH007/7h6ob+V4z0F8+LHnPgxJ36y5iTIwPi/QJmIpH7mMOB4yuvUAn8KXCcikrKvLMDy5ArmxY858WNO/GTNSZCB8RfAWWChiMREZCJwF7CqjfO3AS3AXBGJisgUYFyA5ckVzIsfc+LHnPjJmpPAAqOqNuMKfTvwGfAS8KCqHrzC+dOA7wCngT/DjR+cD6pMuUAbXmp7sxdz4sf6j5+sOglhJunXwPeBvV6BorhB1K1eYT8EJqacfzXwE9xl80Vgd7Znw3LMySmgEZiZ7XqYk5z3Yv0nICdhVWIP7m/7vriB0t8A1bgr1Ene61Lgj4FNwGrgL4AmYGq2v4hsOvHO3wasAwYDs7zGcG2262FOcsuL9Z/wnGRa4MnAf+NyjR5NqcSslHO+D/w07X1vA38OPIIbPP0C99vgjmx/CQF9kZd56aSTa4EE8H89yYs5ad+Jt69X959ccRKli3i33/wDLlofA3aKyHrvcOoU+TeAGhG5K2VfDHgX+DnwG1Ud3NVy5BqtecHVt6NOyoBGVf1a95Q4fMyJH+s/fnLJSZcDI26257Cq/gpARFYBU7xj6XlEP1XV2ekfICLXAleLyABVPZ1BWXKJ1rwsxJyYk8ux/uMnZ5xkMit9HZdH8WNcnniZ5E3gLhH5loho6oYbHBXglIgM9KbkJ2RQplygNS/pN7ebk647+awHO+lU/ykoKOhpbSUjJ5FIRCORSCBOumN1ndtxs4j/ktxRXFzMHXfcQWVlJYWFhcndB3FjSPO6oUzZxuekb9++3H333SxatIjJkycnd/dqJwMHDqSuro5JkyZRUHApjvan9ziBVrzEYjHq6urYs2ePtRWPgoICnn76adauXcvIkSOTu7vsJJPAeJzLs8qH4m7HKVfVTcmdqrpcVUep6lUANTU13HPPPSQSCUaPHs2zzz5LJBJBVYeo6kBVnZZBmXKB1rzUXclJUVERc+fOpby8nDVr1jBixIhe7yQajbJ48WJOnz7N2LFjmT59evLUD3uwk3b7Tzwe58knn+S+++5jxYoVPPTQQz2prXTJSTQaZf78+axbt47HH3+cmTNnJs/rspN2A6OIlInIuyJywFv253veoduBP/H2fwjMBta3/UmOCRMmsH79ejZu3MiyZcsoLS0lFot1ttxZpS0nIvIE7rfYRO/Yt4H7aMfL+PHjuXjxIq+88grHjx+nqKgo9DoETdBObrjhBj755BNefPFFli5dypgxY1KvGvOGoPtPbW0tEydO5MEHH2T58uXEYjEikfxabzpoJ6NHj+bEiRNs376dw4cP09zczOV3BXaejky+XAQWqOpuEbkK+KWI/CcufWIFMAEoBH6sqvXtfdj58+eZNWsW27dv57bbbuO9997j/Pm8S9ZvywnA3wEHgB95/3/9Sl5EhKqqKp577jlEhOrqag4fPkwikWjrLblKYE4ARowYwf79+2lubqayspKjR4/S0tISagVCIrD+U1BQwPz581m1ahVlZWXMmDGD0tLSZLpKPhFoTBkzZgxHjhwhGo0yadIktm7dmrGTdgOjqn6KuzkbVT0jIh/x1YCopmwdarVLliyhqqqKYcOGsWHDBurr2613ztGOE3BfcIe8iAiJRIKpU6dSWFjI7t27+eCDD8IqemgE6QTg448/5oEHHmDcuHHEYjFeeOGFMIodOkH2n0QiwebNm5kyZQrNzc1s2bKFOXPm5N0vjKBjytatW5k3bx7V1dXs2rWL1atXB1LIziRflgOf4BaEfBK4gBvgXAHsBypaec8cYJe3aVtbVxNCs72lOXkCl4x6HlgDfA13u1JF2nsuc1JYWKh9+vRJzsCaE1AR0ZtuuklHjx6t0Wg01cuubNcvIC9d6j8FBQVaXFysffv2vay9ZLtu2XSS7EP9+vULzIl4P6hdRKQf8B6wRFV/JiLVuJVybwf+BvgWsFZV667wGWdwWe2pDAaKVbW0QwXJIVpxMgT4PeAx3Jd2LfA/AG15acMJuFWKrwql4CESkJMG4EvcwgGp9KS2Yv0nPCeQYf/pUIK3iMSAtcBKdaviAhThLSIpIq8CtbSScyQic3ARHtxqvGPj8TixWAxV5dy5c/k4ntaqE1U9KSK34XKxXsWt7PEuMD7tvT4nIkL//v0pKiqiqamJU6dOdVdVAiNAJ4OBwYWFhd8oLS2lpaWFhoYGLl68CP5gmfME3X9isRilpaX06dOHxsZGTp/Ov9zuMJwMGTKESCTCyZMnM563aDcwipve+THwkaqmDvQMSPn/VFwypg9VXQ4s9z5LKysrmTZtGlu2bKGkpIRrrrmGp57Kr+f3tOVEXNZ9kqm4PwV8pDspLCyktraW/v3788477zBz5kweeeSREGsQPEE7KSoqYvHixTQ0NNDU1EQ8Hmfp0qUkEokjIVYjcILuP0OHDmXZsmUMHz6cHTt2MHLkSG699dawih8KQTspLi7mscce4/333+fUqVNMnz6d559/PqMyduSKcSrwAHBeRL6LW8ViDu5G7uEicj/ugTP/weUr67bK/fffz9KlS9m/fz/xeJwlS5YQj8e7XoPs0JaTOuBGXOb9F8Bf4l9x2EdVVRWff/45K1euBOCzz/LuoggCdlJRUYGq8vLLL1NUVMTDDz9MNBqlubk51EqEQKD9Z+HChbS0tFBbW8vZs2d57bXX8jGNKVAnt9xyC4cOHWLjxo2UlJRQVVWVcbpORxKgtgFjVbUPbuD8LG4w/Z9w2ecVuOV+RtJOzpGI0NTUxM0330xlZSX33nsvjY2N+djY23Lyr7gnmh3BPZhnDe3k7CVTdDZv3kw0GqWmpoZ9+/Yl/2zMJwJzAlBWVsaBAwc4d+4c5eXlnDhxggsXLoRZ/rAIrP9EIhHGjh3Lpk2b6NevH48++ih79+7tSf2n004Arr/+eurr64nFYtx5550cPXo0OUnTZTJJ10ngGv3buPte281NU1WeeeYZJk+ezKhRo9i9ezerV6/OuzHGKzgB52UuHfSiqjQ0NLBgwQKOHTvGzp072bZtW8g1CJ4gnQDU19ezaNEibrzxRlSVl156KePGng2C7D+JRIKNGzcye/ZsGhsbeeutt3jjjTfyzkuQTgD27NlDbW0tNTU1HDx4kDfffDOQQnZ1av0JXJTfC7wODGzjPb0xXadTTuLxuA4aNEjj8bg5SWknQ4cO1YqKCi0qKuqJ6Tpd8hKNRnXQoEHpTnp1WxERHTBggJaUlASWrtOZCvQDfglM814PwUX1CLAEF92v9P7JuN8ILbhcpSZPyK9xqRnHcav07gGqs/2FZdnJLlzeX2910uJ5SXdy2juWV04y9cJXi7cmgHOeE+s/IfafjlYghru8fbiN4+XA/iu8vwD4GPgIt+bah8AfAodws5RPAH+V7S+qk19qmE4qcEtt9VYn43G3EOa9k0y9pDj5XdyVVNLFVdZ/wus/HVlEIqM0DI9xuKXKv1TVHbjHH07yKpV3U9Ld4KS1NehymiCdqGrysZl57QQC8ZK6eGsz7iFPU1T1DNZ/Qus/HZmV/iZuar1KRPZ4WzXwrIjsE5G9QCUw/wqf0doClCOBMbgUDnDPgt0rIq+LyMBO16R7CdvJL7x95iS/nUDmXlpdvFVEyrH+E1pb6cis9GZcDlo6GzrzgzyWe/8W4m77eQh3l8M63C1A6v37Q9yT4HKSsJ2o6m9F5Ie41Wh6oxNwXvLaCYTWVpJ3jczD+k84/aebxhP+CHg7ZWzhEPDvXRlb6CmbOTEnnXXivf5rz0uXxuZ6yhZ2W+muFS53AteLyO/gxkgG4h6GBHR6bKGnYE78mBM/l5yISBxYAGzXro/N9RRCbSsdXl0nU7wxhJdxS5efBE54h34AzMDdFaG49IPvqksC7dGYEz/mxI/n5EdAMfB1YB8uTQXMSyhtpTvXRE/NSxPc5e9PVHUDbtr9au+cYbgB1N6AOfFjTvwkF/m9APwKNzdgXkJsK91yxSjuQdqHgD/FfcGvAt8B/hG4G5gOfKGqmS2JkUeYEz/mxE+Kk0m4RwJswrk4ikuO7u1eQmkrHVqPMQBS89OSD9LO6/y0ADAnfsyJn/SH0CfzGOvE//iI3kSobaW7/pTuiflpmWJO/JgTP+3lMZoXR6BtJVvPXUzmHM1T1d8Cy4DhuMHST3E5R70Nc+LHnLTOpTxG83KJQNtKdwXGSw/SFrek+UJgp6Ysf6+qLaqawI0VjOumcmUTc+LHnPhJfwj9MNxdISvNS3htxfIYs4c58WNO/FgeY+tYHmNPxZz4MSd+LI+xdcJsK90WGA3DMPKFbE2+GIZh5CwWGA3DMNKwwGgYhpGGBUbDMIw0LDAahmGkYYHRMAwjDQuMhmEYafw/WgpmptMD5WQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}