{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrya0ni5idIGwB3oe2ye+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/model128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RffrO5RiH_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5a680d30-981d-4efd-a06f-d6a67dd3b7c8"
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000        #\n",
        "batch_size = 64        #\n",
        "image_size=784         #\n",
        "hidden_size=128         #\n",
        "lv_size = 48           # Latent Variable \n",
        "learning_rate=1e-4     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "             nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "def get_prediction(data=xtest):\n",
        "  nn=len(data)\n",
        "  dataloader = DataLoader(DigitDataSet(data), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      tmodel.load_state_dict(torch.load(model_name(i)))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  return np.argmin(diff, axis=1)\n",
        "\n",
        "\n",
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  min_index =get_prediction()\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")\n",
        "  return counts, bins ,len(ytest[min_index != ytest]) , len(ytest)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model,ne=num_epochs,opt=optimizer):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  minloss=100000000\n",
        "  for epoch in range(ne):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      if minloss!=100000000:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "    newlost = float(loss.data ) \n",
        "    if newlost < minloss:\n",
        "        if minloss!=100000000:\n",
        "          save_model(by_digit,model)\n",
        "        minloss=newlost\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, ne, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  \n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ueJ9JLrWxQo",
        "colab_type": "text"
      },
      "source": [
        "**train new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlAu_FKWy9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(by_digit):\n",
        "  train_by_digit(by_digit,model,30)\n",
        "_,_,_,_=testmodel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model and save it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "76101ca1-6050-4b9a-ba46-45bae34a92c6"
      },
      "source": [
        "_,_,_,_=testmodel()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "97.32% accuracy or 2.68% error rate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtOcOgBOmCmg",
        "colab_type": "text"
      },
      "source": [
        "**save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAWdqk10mC-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e82d8a61-5447-48af-9d5e-e8ca6bdcfa6d"
      },
      "source": [
        "!zip -r model.zip ./*.pth"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: ae_0.pth (deflated 6%)\n",
            "updating: ae_1.pth (deflated 5%)\n",
            "updating: ae_2.pth (deflated 6%)\n",
            "updating: ae_3.pth (deflated 7%)\n",
            "updating: ae_4.pth (deflated 8%)\n",
            "updating: ae_5.pth (deflated 7%)\n",
            "updating: ae_6.pth (deflated 9%)\n",
            "updating: ae_7.pth (deflated 10%)\n",
            "updating: ae_8.pth (deflated 10%)\n",
            "updating: ae_9.pth (deflated 10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvTKuQcKae2",
        "colab_type": "text"
      },
      "source": [
        "**retrain the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-dF1c0OKfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traget_error=0.005\n",
        "error = 1\n",
        "while  error > traget_error:\n",
        "  counts,b,fail,total=testmodel()\n",
        "  error = float(fail/total)\n",
        "  if error > traget_error:\n",
        "    train_by_digit(np.argmax(counts),model,30, torch.optim.Adam(model.parameters(), lr=1e-3) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLThtP6wLbe",
        "colab_type": "text"
      },
      "source": [
        "**kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwJitYWwPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/kaggle.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1EI5LMwV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test=pd.read_csv('./test.csv')\n",
        "inputs_test=np.array(inputs_test,dtype=np.float32)\n",
        "inputs_test=inputs_test.reshape(inputs_test.shape[0],28,28)/255\n",
        "y=get_prediction(inputs_test)\n",
        "imageid=1\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "  spamwriter = csv.writer(csvfile, delimiter=' ',    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  spamwriter.writerow(['ImageId,Label'])\n",
        "  for yi in y:\n",
        "    spamwriter.writerow([str(imageid) +','+str( yi)])\n",
        "    imageid+=1\n",
        "#99.714% accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}