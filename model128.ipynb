{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPlulOhoKFSELs7BzhCD64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/model128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RffrO5RiH_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000        #\n",
        "batch_size = 64        #\n",
        "image_size=784         #\n",
        "hidden_size=128         #\n",
        "lv_size = 48           # Latent Variable \n",
        "learning_rate=1e-4     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "             nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "def get_prediction(data=xtest):\n",
        "  nn=len(data)\n",
        "  dataloader = DataLoader(DigitDataSet(data), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      tmodel.load_state_dict(torch.load(model_name(i)))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  return np.argmin(diff, axis=1)\n",
        "\n",
        "\n",
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  min_index =get_prediction()\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")\n",
        "  return counts, bins ,len(ytest[min_index != ytest]) , len(ytest)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model,ne=num_epochs,opt=optimizer):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  minloss=100000000\n",
        "  for epoch in range(ne):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      if minloss!=100000000:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "    newlost = float(loss.data ) \n",
        "    if newlost < minloss:\n",
        "        if minloss!=100000000:\n",
        "          save_model(by_digit,model)\n",
        "        minloss=newlost\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, ne, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  \n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ueJ9JLrWxQo",
        "colab_type": "text"
      },
      "source": [
        "**train new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlAu_FKWy9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for by_digit in range(3):\n",
        "  train_by_digit(by_digit,model,30)\n",
        "_,_,_,_=testmodel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model and save it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "4e081c41-22fb-4a12-acfd-175186820f10"
      },
      "source": [
        "_,_,_,_=testmodel()\n",
        "!zip -r model.zip ./*.pth"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "98.54% accuracy or 1.46% error rate\n",
            "updating: ae_0.pth (deflated 6%)\n",
            "updating: ae_1.pth (deflated 6%)\n",
            "updating: ae_2.pth (deflated 6%)\n",
            "updating: ae_3.pth (deflated 7%)\n",
            "updating: ae_4.pth (deflated 8%)\n",
            "updating: ae_5.pth (deflated 7%)\n",
            "updating: ae_6.pth (deflated 10%)\n",
            "updating: ae_7.pth (deflated 10%)\n",
            "updating: ae_8.pth (deflated 10%)\n",
            "updating: ae_9.pth (deflated 10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvTKuQcKae2",
        "colab_type": "text"
      },
      "source": [
        "**retrain the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-dF1c0OKfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traget_error=0.005\n",
        "error = 1\n",
        "while  error > traget_error:\n",
        "  counts,b,fail,total=testmodel()\n",
        "  error = float(fail/total)\n",
        "  if error > traget_error:\n",
        "    train_by_digit(np.argmax(counts),model,30, torch.optim.Adam(model.parameters(), lr=1e-3) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLThtP6wLbe",
        "colab_type": "text"
      },
      "source": [
        "**kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwJitYWwPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/kaggle.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1EI5LMwV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test=pd.read_csv('./test.csv')\n",
        "inputs_test=np.array(inputs_test,dtype=np.float32)\n",
        "inputs_test=inputs_test.reshape(inputs_test.shape[0],28,28)/255\n",
        "y=get_prediction(inputs_test)\n",
        "imageid=1\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "  spamwriter = csv.writer(csvfile, delimiter=' ',    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  spamwriter.writerow(['ImageId,Label'])\n",
        "  for yi in y:\n",
        "    spamwriter.writerow([str(imageid) +','+str( yi)])\n",
        "    imageid+=1\n",
        "#99.714% accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}