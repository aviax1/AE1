{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUSYLK9TBa3v9c7aIKAoIJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/newindex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RffrO5RiH_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=1000        #\n",
        "batch_size = 64        #\n",
        "image_size=784         #\n",
        "hidden_size=256         #\n",
        "lv_size = 48           # Latent Variable \n",
        "learning_rate=1e-4     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "             nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "def get_prediction(data=xtest):\n",
        "  nn=len(data)\n",
        "  dataloader = DataLoader(DigitDataSet(data), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      tmodel.load_state_dict(torch.load(model_name(i)))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  return np.argmin(diff, axis=1)\n",
        "\n",
        "\n",
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  min_index =get_prediction()\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")\n",
        "  return counts, bins ,len(ytest[min_index != ytest]) , len(ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model,ne=num_epochs,opt=optimizer):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  for epoch in range(ne):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "        \n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, ne, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  save_model(by_digit,model)\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ueJ9JLrWxQo",
        "colab_type": "text"
      },
      "source": [
        "**train new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlAu_FKWy9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd1f38eb-7b24-45fb-837e-9267ef747944"
      },
      "source": [
        "for by_digit in range(10):\n",
        "  train_by_digit(by_digit,model,120)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/369ri4mj\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/369ri4mj</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 0\n",
            "\n",
            "epoch [1/33], loss:0.2540\n",
            "epoch [2/33], loss:0.2346\n",
            "epoch [3/33], loss:0.2498\n",
            "epoch [4/33], loss:0.2494\n",
            "epoch [5/33], loss:0.2427\n",
            "epoch [6/33], loss:0.1962\n",
            "epoch [7/33], loss:0.1874\n",
            "epoch [8/33], loss:0.1951\n",
            "epoch [9/33], loss:0.1958\n",
            "epoch [10/33], loss:0.1897\n",
            "epoch [11/33], loss:0.1944\n",
            "epoch [12/33], loss:0.1762\n",
            "epoch [13/33], loss:0.1581\n",
            "epoch [14/33], loss:0.1594\n",
            "epoch [15/33], loss:0.1626\n",
            "epoch [16/33], loss:0.1446\n",
            "epoch [17/33], loss:0.1418\n",
            "epoch [18/33], loss:0.1449\n",
            "epoch [19/33], loss:0.1406\n",
            "epoch [20/33], loss:0.1246\n",
            "epoch [21/33], loss:0.1211\n",
            "epoch [22/33], loss:0.1230\n",
            "epoch [23/33], loss:0.1256\n",
            "epoch [24/33], loss:0.1252\n",
            "epoch [25/33], loss:0.1281\n",
            "epoch [26/33], loss:0.1179\n",
            "epoch [27/33], loss:0.1205\n",
            "epoch [28/33], loss:0.1134\n",
            "epoch [29/33], loss:0.1204\n",
            "epoch [30/33], loss:0.1252\n",
            "epoch [31/33], loss:0.1160\n",
            "epoch [32/33], loss:0.1064\n",
            "epoch [33/33], loss:0.1082\n",
            "save model ./ae_0.pth\n",
            "\n",
            "finish traning Model Number 0\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/18652qm2\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/18652qm2</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 1\n",
            "\n",
            "epoch [1/33], loss:0.0437\n",
            "epoch [2/33], loss:0.0490\n",
            "epoch [3/33], loss:0.0377\n",
            "epoch [4/33], loss:0.0299\n",
            "epoch [5/33], loss:0.0362\n",
            "epoch [6/33], loss:0.0331\n",
            "epoch [7/33], loss:0.0330\n",
            "epoch [8/33], loss:0.0337\n",
            "epoch [9/33], loss:0.0404\n",
            "epoch [10/33], loss:0.0219\n",
            "epoch [11/33], loss:0.0246\n",
            "epoch [12/33], loss:0.0256\n",
            "epoch [13/33], loss:0.0286\n",
            "epoch [14/33], loss:0.0433\n",
            "epoch [15/33], loss:0.0219\n",
            "epoch [16/33], loss:0.0204\n",
            "epoch [17/33], loss:0.0270\n",
            "epoch [18/33], loss:0.0210\n",
            "epoch [19/33], loss:0.0256\n",
            "epoch [20/33], loss:0.0253\n",
            "epoch [21/33], loss:0.0165\n",
            "epoch [22/33], loss:0.0256\n",
            "epoch [23/33], loss:0.0302\n",
            "epoch [24/33], loss:0.0174\n",
            "epoch [25/33], loss:0.0178\n",
            "epoch [26/33], loss:0.0211\n",
            "epoch [27/33], loss:0.0149\n",
            "epoch [28/33], loss:0.0230\n",
            "epoch [29/33], loss:0.0189\n",
            "epoch [30/33], loss:0.0241\n",
            "epoch [31/33], loss:0.0197\n",
            "epoch [32/33], loss:0.0158\n",
            "epoch [33/33], loss:0.0216\n",
            "save model ./ae_1.pth\n",
            "\n",
            "finish traning Model Number 1\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/3v8y97tx\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/3v8y97tx</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 2\n",
            "\n",
            "epoch [1/33], loss:0.1812\n",
            "epoch [2/33], loss:0.1931\n",
            "epoch [3/33], loss:0.1456\n",
            "epoch [4/33], loss:0.1403\n",
            "epoch [5/33], loss:0.1515\n",
            "epoch [6/33], loss:0.1435\n",
            "epoch [7/33], loss:0.1132\n",
            "epoch [8/33], loss:0.1422\n",
            "epoch [9/33], loss:0.1558\n",
            "epoch [10/33], loss:0.1466\n",
            "epoch [11/33], loss:0.1124\n",
            "epoch [12/33], loss:0.1199\n",
            "epoch [13/33], loss:0.1273\n",
            "epoch [14/33], loss:0.1652\n",
            "epoch [15/33], loss:0.1336\n",
            "epoch [16/33], loss:0.1339\n",
            "epoch [17/33], loss:0.1143\n",
            "epoch [18/33], loss:0.1248\n",
            "epoch [19/33], loss:0.0909\n",
            "epoch [20/33], loss:0.1213\n",
            "epoch [21/33], loss:0.0770\n",
            "epoch [22/33], loss:0.1469\n",
            "epoch [23/33], loss:0.1122\n",
            "epoch [24/33], loss:0.0824\n",
            "epoch [25/33], loss:0.0943\n",
            "epoch [26/33], loss:0.0861\n",
            "epoch [27/33], loss:0.1027\n",
            "epoch [28/33], loss:0.1030\n",
            "epoch [29/33], loss:0.1062\n",
            "epoch [30/33], loss:0.0858\n",
            "epoch [31/33], loss:0.1094\n",
            "epoch [32/33], loss:0.1117\n",
            "epoch [33/33], loss:0.1184\n",
            "save model ./ae_2.pth\n",
            "\n",
            "finish traning Model Number 2\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/wh4qzos3\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/wh4qzos3</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 3\n",
            "\n",
            "epoch [1/33], loss:0.1290\n",
            "epoch [2/33], loss:0.1266\n",
            "epoch [3/33], loss:0.1069\n",
            "epoch [4/33], loss:0.1059\n",
            "epoch [5/33], loss:0.1065\n",
            "epoch [6/33], loss:0.1000\n",
            "epoch [7/33], loss:0.1050\n",
            "epoch [8/33], loss:0.1082\n",
            "epoch [9/33], loss:0.0913\n",
            "epoch [10/33], loss:0.1026\n",
            "epoch [11/33], loss:0.0861\n",
            "epoch [12/33], loss:0.0880\n",
            "epoch [13/33], loss:0.0994\n",
            "epoch [14/33], loss:0.0957\n",
            "epoch [15/33], loss:0.0870\n",
            "epoch [16/33], loss:0.0824\n",
            "epoch [17/33], loss:0.0892\n",
            "epoch [18/33], loss:0.0887\n",
            "epoch [19/33], loss:0.0857\n",
            "epoch [20/33], loss:0.0922\n",
            "epoch [21/33], loss:0.0878\n",
            "epoch [22/33], loss:0.0803\n",
            "epoch [23/33], loss:0.0833\n",
            "epoch [24/33], loss:0.0794\n",
            "epoch [25/33], loss:0.0840\n",
            "epoch [26/33], loss:0.0879\n",
            "epoch [27/33], loss:0.0828\n",
            "epoch [28/33], loss:0.0833\n",
            "epoch [29/33], loss:0.0797\n",
            "epoch [30/33], loss:0.0788\n",
            "epoch [31/33], loss:0.0903\n",
            "epoch [32/33], loss:0.0730\n",
            "epoch [33/33], loss:0.0756\n",
            "save model ./ae_3.pth\n",
            "\n",
            "finish traning Model Number 3\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/fquuenep\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/fquuenep</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 4\n",
            "\n",
            "epoch [1/33], loss:0.1300\n",
            "epoch [2/33], loss:0.1233\n",
            "epoch [3/33], loss:0.1062\n",
            "epoch [4/33], loss:0.0752\n",
            "epoch [5/33], loss:0.0818\n",
            "epoch [6/33], loss:0.0855\n",
            "epoch [7/33], loss:0.0870\n",
            "epoch [8/33], loss:0.0798\n",
            "epoch [9/33], loss:0.0648\n",
            "epoch [10/33], loss:0.0869\n",
            "epoch [11/33], loss:0.0710\n",
            "epoch [12/33], loss:0.0725\n",
            "epoch [13/33], loss:0.0606\n",
            "epoch [14/33], loss:0.0620\n",
            "epoch [15/33], loss:0.0730\n",
            "epoch [16/33], loss:0.0654\n",
            "epoch [17/33], loss:0.0619\n",
            "epoch [18/33], loss:0.0595\n",
            "epoch [19/33], loss:0.0780\n",
            "epoch [20/33], loss:0.0805\n",
            "epoch [21/33], loss:0.0510\n",
            "epoch [22/33], loss:0.0565\n",
            "epoch [23/33], loss:0.0636\n",
            "epoch [24/33], loss:0.0844\n",
            "epoch [25/33], loss:0.0631\n",
            "epoch [26/33], loss:0.0586\n",
            "epoch [27/33], loss:0.0665\n",
            "epoch [28/33], loss:0.0643\n",
            "epoch [29/33], loss:0.0608\n",
            "epoch [30/33], loss:0.0637\n",
            "epoch [31/33], loss:0.0538\n",
            "epoch [32/33], loss:0.0661\n",
            "epoch [33/33], loss:0.0507\n",
            "save model ./ae_4.pth\n",
            "\n",
            "finish traning Model Number 4\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/iy6w2n7h\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/iy6w2n7h</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 5\n",
            "\n",
            "epoch [1/33], loss:0.1247\n",
            "epoch [2/33], loss:0.1182\n",
            "epoch [3/33], loss:0.1122\n",
            "epoch [4/33], loss:0.1030\n",
            "epoch [5/33], loss:0.0846\n",
            "epoch [6/33], loss:0.0900\n",
            "epoch [7/33], loss:0.0956\n",
            "epoch [8/33], loss:0.0824\n",
            "epoch [9/33], loss:0.0910\n",
            "epoch [10/33], loss:0.0822\n",
            "epoch [11/33], loss:0.0823\n",
            "epoch [12/33], loss:0.0848\n",
            "epoch [13/33], loss:0.0814\n",
            "epoch [14/33], loss:0.0776\n",
            "epoch [15/33], loss:0.0805\n",
            "epoch [16/33], loss:0.0826\n",
            "epoch [17/33], loss:0.0686\n",
            "epoch [18/33], loss:0.0713\n",
            "epoch [19/33], loss:0.0862\n",
            "epoch [20/33], loss:0.0679\n",
            "epoch [21/33], loss:0.0737\n",
            "epoch [22/33], loss:0.0737\n",
            "epoch [23/33], loss:0.0688\n",
            "epoch [24/33], loss:0.0746\n",
            "epoch [25/33], loss:0.0745\n",
            "epoch [26/33], loss:0.0661\n",
            "epoch [27/33], loss:0.0639\n",
            "epoch [28/33], loss:0.0732\n",
            "epoch [29/33], loss:0.0694\n",
            "epoch [30/33], loss:0.0682\n",
            "epoch [31/33], loss:0.0689\n",
            "epoch [32/33], loss:0.0766\n",
            "epoch [33/33], loss:0.0641\n",
            "save model ./ae_5.pth\n",
            "\n",
            "finish traning Model Number 5\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/36k0vc00\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/36k0vc00</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 6\n",
            "\n",
            "epoch [1/33], loss:0.0827\n",
            "epoch [2/33], loss:0.0725\n",
            "epoch [3/33], loss:0.0605\n",
            "epoch [4/33], loss:0.0568\n",
            "epoch [5/33], loss:0.0701\n",
            "epoch [6/33], loss:0.0583\n",
            "epoch [7/33], loss:0.0617\n",
            "epoch [8/33], loss:0.0572\n",
            "epoch [9/33], loss:0.0552\n",
            "epoch [10/33], loss:0.0537\n",
            "epoch [11/33], loss:0.0513\n",
            "epoch [12/33], loss:0.0569\n",
            "epoch [13/33], loss:0.0519\n",
            "epoch [14/33], loss:0.0506\n",
            "epoch [15/33], loss:0.0550\n",
            "epoch [16/33], loss:0.0497\n",
            "epoch [17/33], loss:0.0515\n",
            "epoch [18/33], loss:0.0526\n",
            "epoch [19/33], loss:0.0479\n",
            "epoch [20/33], loss:0.0504\n",
            "epoch [21/33], loss:0.0443\n",
            "epoch [22/33], loss:0.0552\n",
            "epoch [23/33], loss:0.0503\n",
            "epoch [24/33], loss:0.0609\n",
            "epoch [25/33], loss:0.0441\n",
            "epoch [26/33], loss:0.0476\n",
            "epoch [27/33], loss:0.0549\n",
            "epoch [28/33], loss:0.0490\n",
            "epoch [29/33], loss:0.0480\n",
            "epoch [30/33], loss:0.0493\n",
            "epoch [31/33], loss:0.0501\n",
            "epoch [32/33], loss:0.0410\n",
            "epoch [33/33], loss:0.0440\n",
            "save model ./ae_6.pth\n",
            "\n",
            "finish traning Model Number 6\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/3sndr1if\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/3sndr1if</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 7\n",
            "\n",
            "epoch [1/33], loss:0.0849\n",
            "epoch [2/33], loss:0.0727\n",
            "epoch [3/33], loss:0.0638\n",
            "epoch [4/33], loss:0.0648\n",
            "epoch [5/33], loss:0.0571\n",
            "epoch [6/33], loss:0.0540\n",
            "epoch [7/33], loss:0.0555\n",
            "epoch [8/33], loss:0.0487\n",
            "epoch [9/33], loss:0.0519\n",
            "epoch [10/33], loss:0.0448\n",
            "epoch [11/33], loss:0.0434\n",
            "epoch [12/33], loss:0.0398\n",
            "epoch [13/33], loss:0.0434\n",
            "epoch [14/33], loss:0.0368\n",
            "epoch [15/33], loss:0.0420\n",
            "epoch [16/33], loss:0.0480\n",
            "epoch [17/33], loss:0.0365\n",
            "epoch [18/33], loss:0.0412\n",
            "epoch [19/33], loss:0.0433\n",
            "epoch [20/33], loss:0.0330\n",
            "epoch [21/33], loss:0.0401\n",
            "epoch [22/33], loss:0.0447\n",
            "epoch [23/33], loss:0.0400\n",
            "epoch [24/33], loss:0.0367\n",
            "epoch [25/33], loss:0.0367\n",
            "epoch [26/33], loss:0.0401\n",
            "epoch [27/33], loss:0.0426\n",
            "epoch [28/33], loss:0.0409\n",
            "epoch [29/33], loss:0.0422\n",
            "epoch [30/33], loss:0.0398\n",
            "epoch [31/33], loss:0.0381\n",
            "epoch [32/33], loss:0.0306\n",
            "epoch [33/33], loss:0.0371\n",
            "save model ./ae_7.pth\n",
            "\n",
            "finish traning Model Number 7\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/1i0am14v\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/1i0am14v</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 8\n",
            "\n",
            "epoch [1/33], loss:0.1080\n",
            "epoch [2/33], loss:0.1081\n",
            "epoch [3/33], loss:0.0959\n",
            "epoch [4/33], loss:0.1052\n",
            "epoch [5/33], loss:0.0935\n",
            "epoch [6/33], loss:0.0848\n",
            "epoch [7/33], loss:0.0990\n",
            "epoch [8/33], loss:0.0925\n",
            "epoch [9/33], loss:0.0808\n",
            "epoch [10/33], loss:0.0818\n",
            "epoch [11/33], loss:0.0828\n",
            "epoch [12/33], loss:0.0836\n",
            "epoch [13/33], loss:0.0868\n",
            "epoch [14/33], loss:0.0829\n",
            "epoch [15/33], loss:0.0789\n",
            "epoch [16/33], loss:0.0696\n",
            "epoch [17/33], loss:0.0788\n",
            "epoch [18/33], loss:0.0903\n",
            "epoch [19/33], loss:0.0669\n",
            "epoch [20/33], loss:0.0653\n",
            "epoch [21/33], loss:0.0699\n",
            "epoch [22/33], loss:0.0725\n",
            "epoch [23/33], loss:0.0722\n",
            "epoch [24/33], loss:0.0758\n",
            "epoch [25/33], loss:0.0680\n",
            "epoch [26/33], loss:0.0756\n",
            "epoch [27/33], loss:0.0781\n",
            "epoch [28/33], loss:0.0771\n",
            "epoch [29/33], loss:0.0687\n",
            "epoch [30/33], loss:0.0759\n",
            "epoch [31/33], loss:0.0735\n",
            "epoch [32/33], loss:0.0718\n",
            "epoch [33/33], loss:0.0849\n",
            "save model ./ae_8.pth\n",
            "\n",
            "finish traning Model Number 8\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/1mwy462g\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/1mwy462g</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 9\n",
            "\n",
            "epoch [1/33], loss:0.0631\n",
            "epoch [2/33], loss:0.0604\n",
            "epoch [3/33], loss:0.0552\n",
            "epoch [4/33], loss:0.0481\n",
            "epoch [5/33], loss:0.0464\n",
            "epoch [6/33], loss:0.0472\n",
            "epoch [7/33], loss:0.0439\n",
            "epoch [8/33], loss:0.0477\n",
            "epoch [9/33], loss:0.0356\n",
            "epoch [10/33], loss:0.0423\n",
            "epoch [11/33], loss:0.0468\n",
            "epoch [12/33], loss:0.0426\n",
            "epoch [13/33], loss:0.0481\n",
            "epoch [14/33], loss:0.0387\n",
            "epoch [15/33], loss:0.0416\n",
            "epoch [16/33], loss:0.0345\n",
            "epoch [17/33], loss:0.0370\n",
            "epoch [18/33], loss:0.0394\n",
            "epoch [19/33], loss:0.0389\n",
            "epoch [20/33], loss:0.0359\n",
            "epoch [21/33], loss:0.0401\n",
            "epoch [22/33], loss:0.0407\n",
            "epoch [23/33], loss:0.0358\n",
            "epoch [24/33], loss:0.0346\n",
            "epoch [25/33], loss:0.0345\n",
            "epoch [26/33], loss:0.0367\n",
            "epoch [27/33], loss:0.0314\n",
            "epoch [28/33], loss:0.0347\n",
            "epoch [29/33], loss:0.0353\n",
            "epoch [30/33], loss:0.0339\n",
            "epoch [31/33], loss:0.0337\n",
            "epoch [32/33], loss:0.0307\n",
            "epoch [33/33], loss:0.0333\n",
            "save model ./ae_9.pth\n",
            "\n",
            "finish traning Model Number 9\n",
            "*****\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "94.25% accuracy or 5.75% error rate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9ce4ebdd-e542-4ebb-e213-e6767f4d5feb"
      },
      "source": [
        "_,_,_,_=testmodel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "98.53% accuracy or 1.47% error rate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvTKuQcKae2",
        "colab_type": "text"
      },
      "source": [
        "**retrain the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-dF1c0OKfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traget_error=0.005\n",
        "error = 1\n",
        "while  error > traget_error:\n",
        "  counts,b,fail,total=testmodel()\n",
        "  error = float(fail/total)\n",
        "  if error > traget_error:\n",
        "    train_by_digit(np.argmax(counts),model,30, torch.optim.Adam(model.parameters(), lr=1e-3) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLThtP6wLbe",
        "colab_type": "text"
      },
      "source": [
        "**kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwJitYWwPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/kaggle.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1EI5LMwV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test=pd.read_csv('./test.csv')\n",
        "inputs_test=np.array(inputs_test,dtype=np.float32)\n",
        "inputs_test=inputs_test.reshape(inputs_test.shape[0],28,28)/255\n",
        "y=get_prediction(inputs_test)\n",
        "imageid=1\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "  spamwriter = csv.writer(csvfile, delimiter=' ',    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  spamwriter.writerow(['ImageId,Label'])\n",
        "  for yi in y:\n",
        "    spamwriter.writerow([str(imageid) +','+str( yi)])\n",
        "    imageid+=1\n",
        "#99.714% accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}