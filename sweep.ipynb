{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZr7PyteqgsZp7fjHGK2xm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RffrO5RiH_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3d48348d-ddc5-4ab7-a9bb-cce271a22cb5"
      },
      "source": [
        "\n",
        "hyperparameter_defaults = dict(\n",
        "    dropout = 0.5,\n",
        "    num_epochs = 10,\n",
        "    channels_two = 32,\n",
        "    batch_size = 100,\n",
        "    learning_rate = 1e-3,\n",
        "    hidden_size=128,\n",
        "    Latent_size=48\n",
        ")\n",
        "wandb.init(config=hyperparameter_defaults,project=\"myproj\")\n",
        "config = wandb.config\n",
        "\n",
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=config.num_epochs        #\n",
        "batch_size=config.batch_size        #\n",
        "image_size=784         #\n",
        "hidden_size=config.hidden_size        #\n",
        "lv_size =config.Latent_size           # Latent Variable \n",
        "learning_rate=config.learning_rate     #\n",
        "cret = nn.MSELoss()    # criterion\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/myproj\" target=\"_blank\">https://app.wandb.ai/aviax1/myproj</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/myproj/runs/1m0s5iiu\" target=\"_blank\">https://app.wandb.ai/aviax1/myproj/runs/1m0s5iiu</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "tmodel=autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLnotTGWCoiu"
      },
      "source": [
        "**classsifcation by train models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650-wSQ1CtXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_name(digit):\n",
        "  return './ae_'+str(digit)+'.pth'\n",
        "\n",
        "def get_prediction(data=xtest):\n",
        "  nn=len(data)\n",
        "  dataloader = DataLoader(DigitDataSet(data), batch_size=nn,shuffle=0 , num_workers=4)\n",
        "  diff = np.zeros( (nn,10),dtype=np.float32 )\n",
        "  for i in range(10):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      tmodel.load_state_dict(torch.load(model_name(i)))\n",
        "      tmodel.eval()\n",
        "      output_imgs = tmodel(imgs)\n",
        "      for i2 in range(len( output_imgs[:,0])):\n",
        "        im_pred=output_imgs.detach().numpy()[i2,:]\n",
        "        im_org=imgs.numpy()[i2,:]\n",
        "        difmat=np.abs(im_pred.reshape(28,28)-im_org.reshape(28,28))\n",
        "        diff[i2,i]=np.sum( np.sum( difmat ))\n",
        "  return np.argmin(diff, axis=1)\n",
        "\n",
        "\n",
        "def testmodel(): \n",
        "  nn=len(ytest)\n",
        "  min_index =get_prediction()\n",
        "  seccess =  min_index == ytest\n",
        "  counts, bins = np.histogram(ytest[ min_index != ytest ])\n",
        "  plt.hist(bins[:-1], bins, weights=counts)\n",
        "  plt.title(\"error by digit\")\n",
        "  plt.show()\n",
        "  accurcy =int(10000*np.sum(seccess))/(nn*100)\n",
        "  error_rate = int(10000*np.sum(min_index != ytest))/(nn*100)\n",
        "  print(str(accurcy) + \"% accuracy or \"+str(error_rate)+\"% error rate\")\n",
        "  return counts, bins ,len(ytest[min_index != ytest]) , len(ytest)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  torch.save(model.state_dict(),mn )\n",
        "  wandb.save(mn)\n",
        "  print(\"save model \"+ mn)\n",
        "\n",
        "def load_model_ifexist(digit,model):\n",
        "  mn=model_name(digit)\n",
        "  if os.path.isfile(mn):\n",
        "    model.load_state_dict(torch.load(mn))\n",
        "    model.eval()\n",
        "  return model\n",
        "\n",
        "def train_by_digit(by_digit,model,ne=num_epochs,opt=optimizer):\n",
        "  model=load_model_ifexist( by_digit,model)\n",
        "  \n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  minloss=100000000\n",
        "  for epoch in range(ne):\n",
        "    run=  epoch%25==0\n",
        "    run2= epoch%125==0 and epoch >0\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      if minloss!=100000000:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "      if run:\n",
        "        run=0\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        pred=model(imgs).detach().numpy()[0,:].reshape(28,28)\n",
        "        wandb.log({\"img\": [wandb.Image(pred, caption=\"preidciton\"),wandb.Image(im, caption=\"original\")]})\n",
        "      if run2:\n",
        "        run2=0\n",
        "        save_model(by_digit,model)\n",
        "        testmodel()\n",
        "    newlost = float(loss.data ) \n",
        "    if newlost < minloss:\n",
        "        if minloss!=100000000:\n",
        "          save_model(by_digit,model)\n",
        "        minloss=newlost\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, ne, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "  \n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n*****\\n\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ueJ9JLrWxQo",
        "colab_type": "text"
      },
      "source": [
        "**train new model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlAu_FKWy9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a53593f6-a73a-4085-c7f4-a21603d3e14d"
      },
      "source": [
        "for by_digit in range(10):\n",
        "  _,_,_,_=testmodel()\n",
        "  train_by_digit(by_digit,model,120,torch.optim.SGD(model.parameters(), lr=1e-4))\n",
        "  _,_,_,_=testmodel()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "98.5% accuracy or 1.5% error rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/1ftjcnvi\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/1ftjcnvi</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 0\n",
            "\n",
            "epoch [1/120], loss:0.0393\n",
            "save model ./ae_0.pth\n",
            "epoch [2/120], loss:0.0383\n",
            "save model ./ae_0.pth\n",
            "epoch [3/120], loss:0.0374\n",
            "epoch [4/120], loss:0.0381\n",
            "save model ./ae_0.pth\n",
            "epoch [5/120], loss:0.0334\n",
            "epoch [6/120], loss:0.0347\n",
            "epoch [7/120], loss:0.0345\n",
            "epoch [8/120], loss:0.0362\n",
            "save model ./ae_0.pth\n",
            "epoch [9/120], loss:0.0308\n",
            "epoch [10/120], loss:0.0318\n",
            "epoch [11/120], loss:0.0342\n",
            "epoch [12/120], loss:0.0337\n",
            "epoch [13/120], loss:0.0330\n",
            "save model ./ae_0.pth\n",
            "epoch [14/120], loss:0.0274\n",
            "epoch [15/120], loss:0.0350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a91ee3c1da23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mby_digit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain_by_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby_digit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c4d4c1451f7d>\u001b[0m in \u001b[0;36mtrain_by_digit\u001b[0;34m(by_digit, model, ne, opt)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminloss\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m100000000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WuduKHmqWo",
        "colab_type": "text"
      },
      "source": [
        "**or used our train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYdY_BmznT99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/models.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFXaatHuocKH",
        "colab_type": "text"
      },
      "source": [
        "**finaly test model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di24IvelKNyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_,_,_,_=testmodel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLThtP6wLbe",
        "colab_type": "text"
      },
      "source": [
        "**kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxwJitYWwPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/aviax1/AE1/\n",
        "!unzip ./AE1/kaggle.zip -d ./\n",
        "!rm -rf ./AE1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i1EI5LMwV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test=pd.read_csv('./test.csv')\n",
        "inputs_test=np.array(inputs_test,dtype=np.float32)\n",
        "inputs_test=inputs_test.reshape(inputs_test.shape[0],28,28)/255\n",
        "y=get_prediction(inputs_test)\n",
        "imageid=1\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "  spamwriter = csv.writer(csvfile, delimiter=' ',    quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "  spamwriter.writerow(['ImageId,Label'])\n",
        "  for yi in y:\n",
        "    spamwriter.writerow([str(imageid) +','+str( yi)])\n",
        "    imageid+=1\n",
        "#99.714% accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}