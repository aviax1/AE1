{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQPtGXboifT9R+5VdWTJmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x0v7Byx0byi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb\n",
        "import torch,wandb,os,warnings,csv\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izl8UpWHyMFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "71355678-6add-4e61-f86f-9e0813809d56"
      },
      "source": [
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'accuracy',\n",
        "      'goal': 'minimize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {\n",
        "            'values': [10, 20, 50,100,200]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.3, 0.4, 0.5,0.6,0.7,0.8]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [16, 32, 25,64]\n",
        "        },\n",
        "        'hidden_size': {\n",
        "            'values': [8,16,24,32, 64, 128,256]\n",
        "        },\n",
        "        'Latent_size': {\n",
        "            'values': [8,12,16,24,32,64]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"aviax1\", project=\"myproj\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: nuavldej\n",
            "Sweep URL: https://app.wandb.ai/aviax1/myproj/sweeps/nuavldej\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVwFL2N3zz2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])\n",
        "\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self,hidden_size,lv_size):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size), \n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "            nn.Linear(hidden_size, hidden_size),nn.ReLU(True),\n",
        "             nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))\n",
        "\n",
        "def train():\n",
        "  config_defaults = {'dropout': 0.5,'num_epochs': 10,'batch_size': 100,'learning_rate': 1e-3,'hidden_size': 128,'Latent_size': 48}\n",
        "  wandb.init(config=config_defaults,project=\"myproj\")\n",
        "  config = wandb.config\n",
        "  (xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "  num_epochs=config.num_epochs        #\n",
        "  batch_size=config.batch_size        #\n",
        "  image_size=784                      #\n",
        "  hidden_size=config.hidden_size      #\n",
        "  lv_size =config.Latent_size         # Latent Variable \n",
        "  learning_rate=config.learning_rate  #\n",
        "  cret = nn.MSELoss()                 # criterion\n",
        "  dropout = config.dropout            #\n",
        "  warnings.filterwarnings('ignore')   #\n",
        "  model = autoencoder(hidden_size,lv_size)\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  model.to(device)\n",
        "  by_digit=0\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-6)\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=6)\n",
        "  for epoch in range(num_epochs):\n",
        "    for data in dataloader:\n",
        "      imgs = Variable(data.view(data.size(0), -1)).to(device)\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "wandb.agent(sweep_id, train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}