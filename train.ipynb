{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRG2ExVKFIO/FqIVdMbZRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnlUAkduSqay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used snniped from https://github.com/L1aoXingyu/pytorch-beginner/\n",
        "import torch\n",
        "import wandb\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from multiprocessing import Process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=130      #\n",
        "batch_size = 8     #\n",
        "image_size=784      #\n",
        "hidden_size=72     #\n",
        "lv_size = 64        # Latent Variable \n",
        "learning_rate=1e-4  #\n",
        "cret = nn.MSELoss() # criterion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, hidden_size),   #nn.ReLU(True), nn.Linear(image_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size), nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "#wandb.watch(model)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])\n",
        "\n",
        "def images_row(dis_images,title,add_to_index=0, images_in_row=5):\n",
        "  if( len(np.shape(dis_images)) == 2):\n",
        "    dis_images=dis_images[0:images_in_row,:]\n",
        "  else:\n",
        "    dis_images=dis_images[0:images_in_row,0,:,:]\n",
        "  for i in range(len(dis_images)):\n",
        "    ax = plt.subplot(30, images_in_row, i+add_to_index + 1)\n",
        "    plt.imshow(dis_images[i].reshape(28, 28))\n",
        "    plt.title( title)\n",
        "    plt.gray()\n",
        "\n",
        "def visual_epoch(epoch_num,model,dataloader):\n",
        "  for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      images_row(input_imgs,\"org \",5*epoch_num)\n",
        "      images_row(output_imgs.detach().numpy(),\"rec \",5*(epoch_num+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train model by digit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "278313fa-4723-43a3-e290-311f7d4a8262"
      },
      "source": [
        "def train_by_digit(by_digit,model):\n",
        "  wandb.init()\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  visual_counter=0\n",
        "  for epoch in range(num_epochs):\n",
        "    run = 1\n",
        "    for data in dataloader:\n",
        "      if run:\n",
        "        run=0\n",
        "        input_imgs = data\n",
        "        imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "        im=data[0,0,:,:].reshape(28,28)\n",
        "        \n",
        "        wandb.log({\"img\": [wandb.Image(im, caption=\"original\")]})\n",
        "\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "    #if epoch%3==0 :\n",
        "    #  visual_epoch(visual_counter,model,dataloader)\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    wandb.log({\"loss\": loss.data})\n",
        "\n",
        "  torch.save(model.state_dict(), './ae_'+str(by_digit)+'.pth')\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n\")\n",
        "  print(\"*****\\n\")\n",
        "\n",
        "for by_digit in range(2,10):\n",
        "  train_by_digit(by_digit,model)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/aviax1/uncategorized\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/aviax1/uncategorized/runs/3kmgq27h\" target=\"_blank\">https://app.wandb.ai/aviax1/uncategorized/runs/3kmgq27h</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 5\n",
            "\n",
            "epoch [1/130], loss:0.0784\n",
            "epoch [2/130], loss:0.0490\n",
            "epoch [3/130], loss:0.0469\n",
            "epoch [4/130], loss:0.0703\n",
            "epoch [5/130], loss:0.0561\n",
            "epoch [6/130], loss:0.0658\n",
            "epoch [7/130], loss:0.0570\n",
            "epoch [8/130], loss:0.0351\n",
            "epoch [9/130], loss:0.0633\n",
            "epoch [10/130], loss:0.0463\n",
            "epoch [11/130], loss:0.0600\n",
            "epoch [12/130], loss:0.0476\n",
            "epoch [13/130], loss:0.0532\n",
            "epoch [14/130], loss:0.0381\n",
            "epoch [15/130], loss:0.0672\n",
            "epoch [16/130], loss:0.0449\n",
            "epoch [17/130], loss:0.0565\n",
            "epoch [18/130], loss:0.0533\n",
            "epoch [19/130], loss:0.0389\n",
            "epoch [20/130], loss:0.0576\n",
            "epoch [21/130], loss:0.0520\n",
            "epoch [22/130], loss:0.0544\n",
            "epoch [23/130], loss:0.0548\n",
            "epoch [24/130], loss:0.0655\n",
            "epoch [25/130], loss:0.0510\n",
            "epoch [26/130], loss:0.0457\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}