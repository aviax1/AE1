{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of myproj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9BaBXreh2uJmg1eHwnOHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviax1/AE1/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtaGi-L_cSaq",
        "colab_type": "text"
      },
      "source": [
        "**dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIO3PVG_grNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used snniped from https://github.com/L1aoXingyu/pytorch-beginner/\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J759cYYvgp4G"
      },
      "source": [
        "**initial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txGJFvD0b_rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(xtrain,ytrain), (xtest,ytest) = mnist.load_data()\n",
        "num_epochs=200      #\n",
        "batch_size = 20    #\n",
        "image_size=784      #\n",
        "hidden_size=128     #\n",
        "lv_size = 64        # Latent Variable \n",
        "learning_rate=1e-4  #\n",
        "cret = nn.MSELoss() # criterion"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyNraKighz1W"
      },
      "source": [
        "**build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUIqLQNnh3-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, image_size),nn.ReLU(True), nn.Linear(image_size, hidden_size),\n",
        "            nn.ReLU(True), nn.Linear(hidden_size, hidden_size), nn.ReLU(True), nn.Linear(hidden_size, lv_size))\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(lv_size, hidden_size),nn.ReLU(True),nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(True),nn.Linear(hidden_size, hidden_size),nn.ReLU(True), nn.Linear(hidden_size, image_size), nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sgQmvLNFnEAs"
      },
      "source": [
        "**model setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGfS3vTnZb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = autoencoder()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "class DigitDataSet(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "      self.dataset = dataset\n",
        "      self.transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      return self.transform( self.dataset[idx,:,:])\n",
        "\n",
        "def images_row(dis_images,title,add_to_index=0, images_in_row=5):\n",
        "  if( len(np.shape(dis_images)) == 2):\n",
        "    dis_images=dis_images[0:images_in_row,:]\n",
        "  else:\n",
        "    dis_images=dis_images[0:images_in_row,0,:,:]\n",
        "  for i in range(len(dis_images)):\n",
        "    ax = plt.subplot(30, images_in_row, i+add_to_index + 1)\n",
        "    plt.imshow(dis_images[i].reshape(28, 28))\n",
        "    plt.title( title)\n",
        "    plt.gray()\n",
        "\n",
        "def visual_epoch(epoch_num,model,dataloader):\n",
        "  for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      images_row(input_imgs,\"org \",5*epoch_num)\n",
        "      images_row(output_imgs.detach().numpy(),\"rec \",5*(epoch_num+1))\n",
        "       "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVPozo4nFAaJ",
        "colab_type": "text"
      },
      "source": [
        "**train model by digit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roL_TvrVC7g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb4e06e7-97f0-4bbf-a90f-203bf1a9adee"
      },
      "source": [
        "for by_digit in range(10):\n",
        "  print(\"*****\\nstart traning Model for digit \" +str(by_digit) +\"\\n\")\n",
        "  dataloader = DataLoader(DigitDataSet(xtrain[ytrain==by_digit]), batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  \n",
        "  visual_counter=0\n",
        "  for epoch in range(num_epochs):\n",
        "    for data in dataloader:\n",
        "      input_imgs = data\n",
        "      imgs = Variable(input_imgs.view(input_imgs.size(0), -1))\n",
        "      output_imgs = model(imgs)\n",
        "      loss = cret(output_imgs, imgs)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    #if epoch%3==0 :\n",
        "    #  visual_epoch(visual_counter,model,dataloader)\n",
        "    print('epoch [{}/{}], loss:{:.4f}' .format(epoch + 1, num_epochs, loss.data))\n",
        "    \n",
        "\n",
        "  torch.save(model.state_dict(), './ae_'+str(by_digit)+'.pth')\n",
        "  print(\"\\nfinish traning Model Number \" +str(by_digit) +\"\\n\")\n",
        "  print(\"*****\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****\n",
            "start traning Model for digit 0\n",
            "\n",
            "epoch [1/200], loss:0.3127\n",
            "epoch [2/200], loss:0.1491\n",
            "epoch [3/200], loss:0.1825\n",
            "epoch [4/200], loss:0.1000\n",
            "epoch [5/200], loss:0.1381\n",
            "epoch [6/200], loss:0.0945\n",
            "epoch [7/200], loss:0.1181\n",
            "epoch [8/200], loss:0.1212\n",
            "epoch [9/200], loss:0.0544\n",
            "epoch [10/200], loss:0.0850\n",
            "epoch [11/200], loss:0.0980\n",
            "epoch [12/200], loss:0.1087\n",
            "epoch [13/200], loss:0.0666\n",
            "epoch [14/200], loss:0.0727\n",
            "epoch [15/200], loss:0.1148\n",
            "epoch [16/200], loss:0.0755\n",
            "epoch [17/200], loss:0.0633\n",
            "epoch [18/200], loss:0.0964\n",
            "epoch [19/200], loss:0.0762\n",
            "epoch [20/200], loss:0.0538\n",
            "epoch [21/200], loss:0.0428\n",
            "epoch [22/200], loss:0.0621\n",
            "epoch [23/200], loss:0.0742\n",
            "epoch [24/200], loss:0.0468\n",
            "epoch [25/200], loss:0.0625\n",
            "epoch [26/200], loss:0.0789\n",
            "epoch [27/200], loss:0.0444\n",
            "epoch [28/200], loss:0.0628\n",
            "epoch [29/200], loss:0.0755\n",
            "epoch [30/200], loss:0.0540\n",
            "epoch [31/200], loss:0.0723\n",
            "epoch [32/200], loss:0.1031\n",
            "epoch [33/200], loss:0.0474\n",
            "epoch [34/200], loss:0.0415\n",
            "epoch [35/200], loss:0.0949\n",
            "epoch [36/200], loss:0.0377\n",
            "epoch [37/200], loss:0.0515\n",
            "epoch [38/200], loss:0.0556\n",
            "epoch [39/200], loss:0.0447\n",
            "epoch [40/200], loss:0.0400\n",
            "epoch [41/200], loss:0.1076\n",
            "epoch [42/200], loss:0.0408\n",
            "epoch [43/200], loss:0.0618\n",
            "epoch [44/200], loss:0.1150\n",
            "epoch [45/200], loss:0.0520\n",
            "epoch [46/200], loss:0.0728\n",
            "epoch [47/200], loss:0.0509\n",
            "epoch [48/200], loss:0.0343\n",
            "epoch [49/200], loss:0.0530\n",
            "epoch [50/200], loss:0.0455\n",
            "epoch [51/200], loss:0.0450\n",
            "epoch [52/200], loss:0.0272\n",
            "epoch [53/200], loss:0.0488\n",
            "epoch [54/200], loss:0.0327\n",
            "epoch [55/200], loss:0.0304\n",
            "epoch [56/200], loss:0.0503\n",
            "epoch [57/200], loss:0.0592\n",
            "epoch [58/200], loss:0.0435\n",
            "epoch [59/200], loss:0.0389\n",
            "epoch [60/200], loss:0.0428\n",
            "epoch [61/200], loss:0.0537\n",
            "epoch [62/200], loss:0.0405\n",
            "epoch [63/200], loss:0.0604\n",
            "epoch [64/200], loss:0.0416\n",
            "epoch [65/200], loss:0.0323\n",
            "epoch [66/200], loss:0.0290\n",
            "epoch [67/200], loss:0.0282\n",
            "epoch [68/200], loss:0.0625\n",
            "epoch [69/200], loss:0.0323\n",
            "epoch [70/200], loss:0.0507\n",
            "epoch [71/200], loss:0.0257\n",
            "epoch [72/200], loss:0.0303\n",
            "epoch [73/200], loss:0.0327\n",
            "epoch [74/200], loss:0.0419\n",
            "epoch [75/200], loss:0.0277\n",
            "epoch [76/200], loss:0.0476\n",
            "epoch [77/200], loss:0.0290\n",
            "epoch [78/200], loss:0.0284\n",
            "epoch [79/200], loss:0.0382\n",
            "epoch [80/200], loss:0.0526\n",
            "epoch [81/200], loss:0.0334\n",
            "epoch [82/200], loss:0.0465\n",
            "epoch [83/200], loss:0.0490\n",
            "epoch [84/200], loss:0.0552\n",
            "epoch [85/200], loss:0.0545\n",
            "epoch [86/200], loss:0.0344\n",
            "epoch [87/200], loss:0.0264\n",
            "epoch [88/200], loss:0.0495\n",
            "epoch [89/200], loss:0.0438\n",
            "epoch [90/200], loss:0.0392\n",
            "epoch [91/200], loss:0.0637\n",
            "epoch [92/200], loss:0.0421\n",
            "epoch [93/200], loss:0.0455\n",
            "epoch [94/200], loss:0.0280\n",
            "epoch [95/200], loss:0.0329\n",
            "epoch [96/200], loss:0.0287\n",
            "epoch [97/200], loss:0.0478\n",
            "epoch [98/200], loss:0.0420\n",
            "epoch [99/200], loss:0.0228\n",
            "epoch [100/200], loss:0.0319\n",
            "epoch [101/200], loss:0.0204\n",
            "epoch [102/200], loss:0.0423\n",
            "epoch [103/200], loss:0.0457\n",
            "epoch [104/200], loss:0.0310\n",
            "epoch [105/200], loss:0.0544\n",
            "epoch [106/200], loss:0.0319\n",
            "epoch [107/200], loss:0.0263\n",
            "epoch [108/200], loss:0.0281\n",
            "epoch [109/200], loss:0.0373\n",
            "epoch [110/200], loss:0.0386\n",
            "epoch [111/200], loss:0.0258\n",
            "epoch [112/200], loss:0.0181\n",
            "epoch [113/200], loss:0.0315\n",
            "epoch [114/200], loss:0.0367\n",
            "epoch [115/200], loss:0.0278\n",
            "epoch [116/200], loss:0.0479\n",
            "epoch [117/200], loss:0.0302\n",
            "epoch [118/200], loss:0.0510\n",
            "epoch [119/200], loss:0.0300\n",
            "epoch [120/200], loss:0.0510\n",
            "epoch [121/200], loss:0.0327\n",
            "epoch [122/200], loss:0.0309\n",
            "epoch [123/200], loss:0.0402\n",
            "epoch [124/200], loss:0.0474\n",
            "epoch [125/200], loss:0.0233\n",
            "epoch [126/200], loss:0.0332\n",
            "epoch [127/200], loss:0.0357\n",
            "epoch [128/200], loss:0.0259\n",
            "epoch [129/200], loss:0.0221\n",
            "epoch [130/200], loss:0.0230\n",
            "epoch [131/200], loss:0.0276\n",
            "epoch [132/200], loss:0.0343\n",
            "epoch [133/200], loss:0.0352\n",
            "epoch [134/200], loss:0.0314\n",
            "epoch [135/200], loss:0.0257\n",
            "epoch [136/200], loss:0.0320\n",
            "epoch [137/200], loss:0.0239\n",
            "epoch [138/200], loss:0.0271\n",
            "epoch [139/200], loss:0.0410\n",
            "epoch [140/200], loss:0.0337\n",
            "epoch [141/200], loss:0.0228\n",
            "epoch [142/200], loss:0.0311\n",
            "epoch [143/200], loss:0.0271\n",
            "epoch [144/200], loss:0.0325\n",
            "epoch [145/200], loss:0.0445\n",
            "epoch [146/200], loss:0.0339\n",
            "epoch [147/200], loss:0.0314\n",
            "epoch [148/200], loss:0.0251\n",
            "epoch [149/200], loss:0.0275\n",
            "epoch [150/200], loss:0.0305\n",
            "epoch [151/200], loss:0.0286\n",
            "epoch [152/200], loss:0.0460\n",
            "epoch [153/200], loss:0.0580\n",
            "epoch [154/200], loss:0.0291\n",
            "epoch [155/200], loss:0.0224\n",
            "epoch [156/200], loss:0.0337\n",
            "epoch [157/200], loss:0.0226\n",
            "epoch [158/200], loss:0.0513\n",
            "epoch [159/200], loss:0.0345\n",
            "epoch [160/200], loss:0.0268\n",
            "epoch [161/200], loss:0.0265\n",
            "epoch [162/200], loss:0.0606\n",
            "epoch [163/200], loss:0.0324\n",
            "epoch [164/200], loss:0.0310\n",
            "epoch [165/200], loss:0.0307\n",
            "epoch [166/200], loss:0.0332\n",
            "epoch [167/200], loss:0.0198\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}